{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "import re\n",
    "import glob\n",
    "import time\n",
    "import itertools\n",
    "from multiprocessing import Pool\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicFile():\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.file_name = file_path.split('/')[-1]\n",
    "        self.audio, _ = librosa.core.load(file_path, duration=25)\n",
    "        self.genre = file_path.split('/')[-2]\n",
    "\n",
    "    def flourier_transform(self):\n",
    "        return librosa.core.stft(self.audio)\n",
    "\n",
    "    def mel_spectrogram(self):\n",
    "        return librosa.feature.melspectrogram(self.audio)\n",
    "\n",
    "    def mel_chroma(self):\n",
    "        return librosa.feature.chroma_stft(self.audio)\n",
    "\n",
    "class MusicFileGrapher():\n",
    "    def __init__(self, music_file):\n",
    "        self.music_file = music_file\n",
    "\n",
    "    def graph_ft(self):\n",
    "        self.graph(self.music_file.flourier_transform())\n",
    "        \n",
    "    def graph_ms(self):\n",
    "        self.graph(self.music_file.mel_spectrogram())\n",
    "        \n",
    "    def graph_chroma(self):\n",
    "        self.graph(self.music_file.mel_chroma)\n",
    "        \n",
    "    def graph(self, data):\n",
    "        Xdb = librosa.amplitude_to_db(data)\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        librosa.display.specshow(Xdb, x_axis='time', y_axis='hz')\n",
    "        plt.xlabel(self.music_file.file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 46.46477675437927\n"
     ]
    }
   ],
   "source": [
    "all_file_paths = glob.glob('genres/*/*.au')\n",
    "\n",
    "def add_music_file(audio_file_path):\n",
    "    return MusicFile(audio_file_path)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "p = Pool(20)\n",
    "music_files = p.map(add_music_file, all_file_paths)\n",
    "\n",
    "print(\"Took\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = sorted(set(map(lambda music_file: music_file.genre, music_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_to_int(genre):\n",
    "    return all_genres.index(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_to_onehot(genre):\n",
    "    array = np.zeros(len(all_genres))\n",
    "    array[genre_to_int(genre)] = 1\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_to_onehot('reggae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_files = sorted(music_files, key=lambda music_file: music_file.file_path)\n",
    "\n",
    "mel_x_train = []\n",
    "stft_x_train = []\n",
    "y_train = []\n",
    "\n",
    "mel_x_test = []\n",
    "stft_x_test = []\n",
    "y_test = []\n",
    "\n",
    "for genre, genre_music_file_group in itertools.groupby(music_files, key=lambda music_file: music_file.genre):\n",
    "    one_hot_genre = genre_to_onehot(genre)\n",
    "    for i, music_file in enumerate(genre_music_file_group):\n",
    "        if i < 70:\n",
    "            mel_x_train.append(music_file.mel_spectrogram())\n",
    "            stft_x_train.append(music_file.flourier_transform())\n",
    "\n",
    "            y_train.append(one_hot_genre)\n",
    "        else:\n",
    "            mel_x_test.append(music_file.mel_spectrogram())\n",
    "            stft_x_test.append(music_file.flourier_transform())\n",
    "\n",
    "            y_test.append(one_hot_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_total_max = max(np.max(mel_x_train), np.max(mel_x_test))\n",
    "\n",
    "mel_normalized_x_train = np.array(mel_x_train) / mel_total_max\n",
    "mel_normalized_x_test = np.array(mel_x_test) / mel_total_max\n",
    "\n",
    "mel_normalized_x_train = mel_normalized_x_train.reshape((*mel_normalized_x_train.shape, 1))\n",
    "mel_normalized_x_test = mel_normalized_x_test.reshape((*mel_normalized_x_test.shape, 1))\n",
    "\n",
    "stft_total_max = max(np.max(stft_x_train), np.max(stft_x_test))\n",
    "\n",
    "stft_normalized_x_train = np.array(stft_x_train) / stft_total_max\n",
    "stft_normalized_x_test = np.array(stft_x_test) / stft_total_max\n",
    "\n",
    "stft_normalized_x_train = stft_normalized_x_train.reshape((*stft_normalized_x_train.shape, 1))\n",
    "stft_normalized_x_test = stft_normalized_x_test.reshape((*stft_normalized_x_test.shape, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0622 16:48:04.719112 139829181630208 deprecation.py:506] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 1077, 64)     320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 538, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 538, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 538, 32)       8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 269, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 269, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 275456)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               70516992  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 70,528,106\n",
      "Trainable params: 70,528,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mel_model = tf.keras.models.Sequential()\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "mel_model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=mel_normalized_x_train[0].shape)) \n",
    "mel_model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "mel_model.add(tf.keras.layers.Dropout(0.3))\n",
    "mel_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "mel_model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "mel_model.add(tf.keras.layers.Dropout(0.5))\n",
    "mel_model.add(tf.keras.layers.Flatten())\n",
    "mel_model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "mel_model.add(tf.keras.layers.Dropout(0.5))\n",
    "mel_model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "# Take a look at the model summary\n",
    "mel_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 630 samples, validate on 70 samples\n",
      "Epoch 1/10\n",
      "630/630 [==============================] - 30s 48ms/sample - loss: 2.2689 - acc: 0.1190 - val_loss: 2.8750 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "630/630 [==============================] - 26s 42ms/sample - loss: 2.1284 - acc: 0.1492 - val_loss: 3.0444 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "630/630 [==============================] - 26s 42ms/sample - loss: 2.0071 - acc: 0.2460 - val_loss: 4.1041 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "630/630 [==============================] - 26s 42ms/sample - loss: 1.9352 - acc: 0.2921 - val_loss: 4.3129 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "630/630 [==============================] - 26s 42ms/sample - loss: 1.8471 - acc: 0.3619 - val_loss: 4.8524 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "630/630 [==============================] - 26s 41ms/sample - loss: 1.7074 - acc: 0.3921 - val_loss: 5.4990 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "630/630 [==============================] - 27s 42ms/sample - loss: 1.6019 - acc: 0.4619 - val_loss: 5.2246 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "630/630 [==============================] - 27s 43ms/sample - loss: 1.5021 - acc: 0.4968 - val_loss: 6.6964 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "630/630 [==============================] - 26s 42ms/sample - loss: 1.3055 - acc: 0.5730 - val_loss: 8.1404 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "630/630 [==============================] - 26s 42ms/sample - loss: 1.1270 - acc: 0.6444 - val_loss: 8.2901 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2bf840a4e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_model.fit(mel_normalized_x_train,\n",
    "         np.array(y_train),\n",
    "         batch_size=100,\n",
    "         epochs=10,\n",
    "         validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test accuracy: 0.31\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "score = mel_model.evaluate(mel_normalized_x_test, np.array(y_test), verbose=0)\n",
    "# Print test accuracy\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0622 17:02:58.283594 139829553825536 deprecation.py:506] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 1025, 1077, 64)    320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 512, 538, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512, 538, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 512, 538, 32)      8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 256, 269, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256, 269, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2203648)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               564134144 \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 564,145,258\n",
      "Trainable params: 564,145,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "stft_model = tf.keras.models.Sequential()\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "stft_model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=stft_normalized_x_train[0].shape)) \n",
    "stft_model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "stft_model.add(tf.keras.layers.Dropout(0.3))\n",
    "stft_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "stft_model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "stft_model.add(tf.keras.layers.Dropout(0.5))\n",
    "stft_model.add(tf.keras.layers.Flatten())\n",
    "stft_model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "stft_model.add(tf.keras.layers.Dropout(0.5))\n",
    "stft_model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "# Take a look at the model summary\n",
    "stft_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_model.fit(abs(stft_normalized_x_train),\n",
    "         np.array(y_train),\n",
    "         batch_size=60,\n",
    "         epochs=10,\n",
    "         validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test set\n",
    "score = stft_model.evaluate(stft_normalized_x_test, np.array(y_test), verbose=0)\n",
    "# Print test accuracy\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
